{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will forecast electricity load using Multi-layer perceptron. This is one of the example of using MLP for time-series prediction. Before building a neural network we would first visualize the dataset and preprocess it if it seems necessary.\n",
    "\n",
    "The dataset is provided at [OpenDataNepal.Net](https://opendatanepal.com/dataset/electricity-load-profile-of-nepal-in-2073-nepal-electricity-authority). The dataset is for the year 2073 B.S and the data load profile is given for each 12 months(Baisakh to Chaitra). Also, the data provided is not for each hour it is given at an interval of 1 hour for 1AM to 5AM, and from 5AM to 9PM it is given at an interval of 30 minutes.\n",
    "\n",
    "First we will combine all the 12 months data into a single data frame using pandas and combine load hours. The preprocessed dataset is provided with this notebook as **Load_Profile_Data_2073.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Load_Profile_Data_2073.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1:00</th>\n",
       "      <th>2:00</th>\n",
       "      <th>3:00</th>\n",
       "      <th>4:00</th>\n",
       "      <th>5:00</th>\n",
       "      <th>6:00</th>\n",
       "      <th>7:00</th>\n",
       "      <th>8:00</th>\n",
       "      <th>9:00</th>\n",
       "      <th>10:00</th>\n",
       "      <th>...</th>\n",
       "      <th>15:00</th>\n",
       "      <th>16:00</th>\n",
       "      <th>17:00</th>\n",
       "      <th>18:00</th>\n",
       "      <th>19:00</th>\n",
       "      <th>20:00</th>\n",
       "      <th>21:00</th>\n",
       "      <th>22:00</th>\n",
       "      <th>23:00</th>\n",
       "      <th>0:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>717.49</td>\n",
       "      <td>707.64</td>\n",
       "      <td>706.44</td>\n",
       "      <td>737.34</td>\n",
       "      <td>745.09</td>\n",
       "      <td>1540.13</td>\n",
       "      <td>1599.88</td>\n",
       "      <td>1575.38</td>\n",
       "      <td>735.64</td>\n",
       "      <td>736.24</td>\n",
       "      <td>...</td>\n",
       "      <td>670.24</td>\n",
       "      <td>672.74</td>\n",
       "      <td>659.04</td>\n",
       "      <td>1262.68</td>\n",
       "      <td>1785.88</td>\n",
       "      <td>2237.78</td>\n",
       "      <td>2178.08</td>\n",
       "      <td>773.74</td>\n",
       "      <td>725.29</td>\n",
       "      <td>682.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>651.39</td>\n",
       "      <td>636.34</td>\n",
       "      <td>615.34</td>\n",
       "      <td>623.74</td>\n",
       "      <td>656.19</td>\n",
       "      <td>1375.33</td>\n",
       "      <td>1608.88</td>\n",
       "      <td>1717.48</td>\n",
       "      <td>880.74</td>\n",
       "      <td>863.34</td>\n",
       "      <td>...</td>\n",
       "      <td>904.54</td>\n",
       "      <td>890.94</td>\n",
       "      <td>837.94</td>\n",
       "      <td>1703.48</td>\n",
       "      <td>2216.28</td>\n",
       "      <td>2374.08</td>\n",
       "      <td>2304.18</td>\n",
       "      <td>835.04</td>\n",
       "      <td>802.89</td>\n",
       "      <td>772.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>754.89</td>\n",
       "      <td>744.44</td>\n",
       "      <td>729.04</td>\n",
       "      <td>724.74</td>\n",
       "      <td>769.39</td>\n",
       "      <td>1627.63</td>\n",
       "      <td>1763.18</td>\n",
       "      <td>1827.68</td>\n",
       "      <td>933.04</td>\n",
       "      <td>848.64</td>\n",
       "      <td>...</td>\n",
       "      <td>903.94</td>\n",
       "      <td>877.84</td>\n",
       "      <td>854.94</td>\n",
       "      <td>1888.78</td>\n",
       "      <td>2157.98</td>\n",
       "      <td>2095.28</td>\n",
       "      <td>2245.88</td>\n",
       "      <td>824.44</td>\n",
       "      <td>828.49</td>\n",
       "      <td>803.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751.79</td>\n",
       "      <td>746.94</td>\n",
       "      <td>723.24</td>\n",
       "      <td>732.94</td>\n",
       "      <td>727.89</td>\n",
       "      <td>1511.43</td>\n",
       "      <td>1628.18</td>\n",
       "      <td>1777.18</td>\n",
       "      <td>904.24</td>\n",
       "      <td>914.44</td>\n",
       "      <td>...</td>\n",
       "      <td>903.84</td>\n",
       "      <td>852.14</td>\n",
       "      <td>784.14</td>\n",
       "      <td>1017.58</td>\n",
       "      <td>2035.72</td>\n",
       "      <td>1386.08</td>\n",
       "      <td>1036.88</td>\n",
       "      <td>826.94</td>\n",
       "      <td>771.89</td>\n",
       "      <td>767.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722.89</td>\n",
       "      <td>596.24</td>\n",
       "      <td>595.24</td>\n",
       "      <td>595.24</td>\n",
       "      <td>635.19</td>\n",
       "      <td>1409.83</td>\n",
       "      <td>1556.18</td>\n",
       "      <td>1550.68</td>\n",
       "      <td>728.74</td>\n",
       "      <td>778.04</td>\n",
       "      <td>...</td>\n",
       "      <td>383.54</td>\n",
       "      <td>862.14</td>\n",
       "      <td>702.04</td>\n",
       "      <td>1708.98</td>\n",
       "      <td>2111.48</td>\n",
       "      <td>2385.98</td>\n",
       "      <td>2113.38</td>\n",
       "      <td>810.44</td>\n",
       "      <td>797.39</td>\n",
       "      <td>764.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>593.50</td>\n",
       "      <td>613.80</td>\n",
       "      <td>652.70</td>\n",
       "      <td>641.90</td>\n",
       "      <td>651.70</td>\n",
       "      <td>1373.80</td>\n",
       "      <td>1624.80</td>\n",
       "      <td>1841.70</td>\n",
       "      <td>899.60</td>\n",
       "      <td>850.40</td>\n",
       "      <td>...</td>\n",
       "      <td>852.60</td>\n",
       "      <td>847.80</td>\n",
       "      <td>103.50</td>\n",
       "      <td>1675.30</td>\n",
       "      <td>2201.70</td>\n",
       "      <td>2313.50</td>\n",
       "      <td>2219.70</td>\n",
       "      <td>784.20</td>\n",
       "      <td>749.10</td>\n",
       "      <td>720.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>692.30</td>\n",
       "      <td>685.60</td>\n",
       "      <td>683.70</td>\n",
       "      <td>698.60</td>\n",
       "      <td>699.60</td>\n",
       "      <td>1546.60</td>\n",
       "      <td>1701.70</td>\n",
       "      <td>1816.20</td>\n",
       "      <td>899.50</td>\n",
       "      <td>870.00</td>\n",
       "      <td>...</td>\n",
       "      <td>784.90</td>\n",
       "      <td>816.90</td>\n",
       "      <td>771.80</td>\n",
       "      <td>1703.40</td>\n",
       "      <td>2018.40</td>\n",
       "      <td>2258.10</td>\n",
       "      <td>2118.70</td>\n",
       "      <td>734.10</td>\n",
       "      <td>718.40</td>\n",
       "      <td>682.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>623.70</td>\n",
       "      <td>607.70</td>\n",
       "      <td>605.50</td>\n",
       "      <td>610.10</td>\n",
       "      <td>643.00</td>\n",
       "      <td>1418.60</td>\n",
       "      <td>1588.70</td>\n",
       "      <td>1699.30</td>\n",
       "      <td>871.90</td>\n",
       "      <td>848.60</td>\n",
       "      <td>...</td>\n",
       "      <td>856.60</td>\n",
       "      <td>868.40</td>\n",
       "      <td>802.50</td>\n",
       "      <td>1473.70</td>\n",
       "      <td>1612.90</td>\n",
       "      <td>1744.20</td>\n",
       "      <td>1705.30</td>\n",
       "      <td>784.50</td>\n",
       "      <td>745.40</td>\n",
       "      <td>730.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>693.70</td>\n",
       "      <td>682.30</td>\n",
       "      <td>669.50</td>\n",
       "      <td>686.70</td>\n",
       "      <td>715.70</td>\n",
       "      <td>1535.20</td>\n",
       "      <td>1729.10</td>\n",
       "      <td>1843.40</td>\n",
       "      <td>934.80</td>\n",
       "      <td>903.60</td>\n",
       "      <td>...</td>\n",
       "      <td>860.40</td>\n",
       "      <td>871.10</td>\n",
       "      <td>896.20</td>\n",
       "      <td>1667.30</td>\n",
       "      <td>2153.60</td>\n",
       "      <td>2301.80</td>\n",
       "      <td>2065.90</td>\n",
       "      <td>814.70</td>\n",
       "      <td>784.90</td>\n",
       "      <td>767.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>708.00</td>\n",
       "      <td>709.30</td>\n",
       "      <td>651.70</td>\n",
       "      <td>688.40</td>\n",
       "      <td>750.40</td>\n",
       "      <td>1531.70</td>\n",
       "      <td>1669.90</td>\n",
       "      <td>1829.00</td>\n",
       "      <td>936.90</td>\n",
       "      <td>917.40</td>\n",
       "      <td>...</td>\n",
       "      <td>886.00</td>\n",
       "      <td>887.10</td>\n",
       "      <td>812.90</td>\n",
       "      <td>1852.40</td>\n",
       "      <td>2178.80</td>\n",
       "      <td>2376.40</td>\n",
       "      <td>2292.60</td>\n",
       "      <td>829.30</td>\n",
       "      <td>790.50</td>\n",
       "      <td>759.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1:00    2:00    3:00    4:00    5:00     6:00     7:00     8:00  \\\n",
       "0    717.49  707.64  706.44  737.34  745.09  1540.13  1599.88  1575.38   \n",
       "1    651.39  636.34  615.34  623.74  656.19  1375.33  1608.88  1717.48   \n",
       "2    754.89  744.44  729.04  724.74  769.39  1627.63  1763.18  1827.68   \n",
       "3    751.79  746.94  723.24  732.94  727.89  1511.43  1628.18  1777.18   \n",
       "4    722.89  596.24  595.24  595.24  635.19  1409.83  1556.18  1550.68   \n",
       "..      ...     ...     ...     ...     ...      ...      ...      ...   \n",
       "360  593.50  613.80  652.70  641.90  651.70  1373.80  1624.80  1841.70   \n",
       "361  692.30  685.60  683.70  698.60  699.60  1546.60  1701.70  1816.20   \n",
       "362  623.70  607.70  605.50  610.10  643.00  1418.60  1588.70  1699.30   \n",
       "363  693.70  682.30  669.50  686.70  715.70  1535.20  1729.10  1843.40   \n",
       "364  708.00  709.30  651.70  688.40  750.40  1531.70  1669.90  1829.00   \n",
       "\n",
       "       9:00   10:00  ...   15:00   16:00   17:00    18:00    19:00    20:00  \\\n",
       "0    735.64  736.24  ...  670.24  672.74  659.04  1262.68  1785.88  2237.78   \n",
       "1    880.74  863.34  ...  904.54  890.94  837.94  1703.48  2216.28  2374.08   \n",
       "2    933.04  848.64  ...  903.94  877.84  854.94  1888.78  2157.98  2095.28   \n",
       "3    904.24  914.44  ...  903.84  852.14  784.14  1017.58  2035.72  1386.08   \n",
       "4    728.74  778.04  ...  383.54  862.14  702.04  1708.98  2111.48  2385.98   \n",
       "..      ...     ...  ...     ...     ...     ...      ...      ...      ...   \n",
       "360  899.60  850.40  ...  852.60  847.80  103.50  1675.30  2201.70  2313.50   \n",
       "361  899.50  870.00  ...  784.90  816.90  771.80  1703.40  2018.40  2258.10   \n",
       "362  871.90  848.60  ...  856.60  868.40  802.50  1473.70  1612.90  1744.20   \n",
       "363  934.80  903.60  ...  860.40  871.10  896.20  1667.30  2153.60  2301.80   \n",
       "364  936.90  917.40  ...  886.00  887.10  812.90  1852.40  2178.80  2376.40   \n",
       "\n",
       "       21:00   22:00   23:00    0:00  \n",
       "0    2178.08  773.74  725.29  682.14  \n",
       "1    2304.18  835.04  802.89  772.94  \n",
       "2    2245.88  824.44  828.49  803.94  \n",
       "3    1036.88  826.94  771.89  767.84  \n",
       "4    2113.38  810.44  797.39  764.24  \n",
       "..       ...     ...     ...     ...  \n",
       "360  2219.70  784.20  749.10  720.10  \n",
       "361  2118.70  734.10  718.40  682.90  \n",
       "362  1705.30  784.50  745.40  730.70  \n",
       "363  2065.90  814.70  784.90  767.00  \n",
       "364  2292.60  829.30  790.50  759.30  \n",
       "\n",
       "[365 rows x 24 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing with time series prediction is the count of previous sequence we want to use. In this case we may use data of previous 3 days or 4 days or 10 days. In this project, we are going to use datas from previous 3 days.\n",
    "\n",
    "Another interesting thing with time series prediction is **Test Cases**. Generally test cases are splitted from overall dataset in certail ration like 80:20, 70:30 depending upon the size of datasets(If we have a very large dataset then 90:10 split will provide sufficient test cases). The neural net will not see the test cases during training. So they are very important to see the generalization of our neural net. \n",
    "\n",
    "The problem is if we drop any data from our dataset then the train data will not be in sequence. Say we have a problem of dertermining next number given 2 inputs and data as 1,2,3,4,5,6,7,8,9,10 and if we drop 5,6 for testing then the remaining data will not be in sequence. So what we will do is given a sequence we will transform that sequence into individual datapoints as [1,2], [2,3], [3,4] ... and also the label will be 3, 4 .... . Now we can randomize the datapoints and drop certain input for testing too as individual datapoints are always in sequence. \n",
    "\n",
    "\n",
    "So, for the Electricity load profile let's breakdown the year-long data into individual datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First change the data from pandas dataframe to numpy array\n",
    "data = np.array(dataset)\n",
    "data = data/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 24)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = list()\n",
    "labelpoints = list()\n",
    "\n",
    "split_count = 3 # we are going to seperate each 3 sequence\n",
    "for row in range(data.shape[0] - split_count):\n",
    "    datapoints.append(data[row:row+split_count, :])\n",
    "    labelpoints.append(data[row+split_count])\n",
    "    \n",
    "\n",
    "## Just taking first 14 hours\n",
    "datapoints = np.array(datapoints)[:, :, :14]\n",
    "labelpoints = np.array(labelpoints)[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362, 3, 14) (362, 14)\n"
     ]
    }
   ],
   "source": [
    "print(datapoints.shape, labelpoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 14*3\n",
    "hidden_size = 20\n",
    "output_size = labelpoints.shape[1]\n",
    "\n",
    "weight_input_hidden = 0.2 * np.random.random((input_size, hidden_size)) - 0.1\n",
    "weight_hidden_output = 0.2 * np.random.random((hidden_size, output_size)) - 0.1\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return (x>=0) * x # returns x if x>=0, else 0\n",
    "\n",
    "def relu2deriv(x):\n",
    "    return x>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.92750282512371\n",
      "0.6402991255285938\n",
      "0.6208060175379133\n",
      "0.6202901110558504\n",
      "0.6197818948188362\n",
      "0.6192729643854374\n",
      "0.6187630754028478\n",
      "0.6182521133429449\n",
      "0.6177399798004259\n",
      "0.6172265642156867\n",
      "0.6167117449857243\n",
      "0.616195414198664\n",
      "0.6156774649907351\n",
      "0.6151577915590487\n",
      "0.6146362891620291\n",
      "0.6141128541219589\n",
      "0.6135873838298076\n",
      "0.6130597767523391\n",
      "0.6125299324414923\n",
      "0.6119977515460227\n",
      "0.6114631358254069\n",
      "0.6109259881659856\n",
      "0.610386212599357\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 200\n",
    "alpha = 0.005\n",
    "\n",
    "for itera in range(num_iterations):\n",
    "    error = 0\n",
    "    \n",
    "    for idx in range(datapoints.shape[0]):\n",
    "        label = labelpoints[idx].reshape((14, 1))\n",
    "        layer_0 = datapoints[idx].reshape((input_size, 1))\n",
    "        layer_1 = relu(weight_input_hidden.T.dot(layer_0))\n",
    "        output = weight_hidden_output.T.dot(layer_1)\n",
    "        error = error + np.sum((output - label)**2)\n",
    "        \n",
    "        delta_output = output - label\n",
    "#         print(output[0:2], label[0:2])\n",
    "        delta_layer_1 = weight_hidden_output.dot(delta_output) * relu2deriv(layer_1)\n",
    "        \n",
    "        weight_hidden_output = weight_hidden_output - alpha * layer_1.dot(delta_output.T)\n",
    "        weight_input_hidden = weight_input_hidden - alpha * layer_0.dot(delta_layer_1.T)\n",
    "    if itera % 9 == 0:    \n",
    "        print(error)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
